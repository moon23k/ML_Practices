{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그래디언트 부스팅 회귀 트리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래디언트 부스팅 회귀 트리는 여러 개의 결정 트리를 묶어서 강력한 모델을 만드는 또 다른 앙상블 기법이다.\n",
    "이름이 회귀이지만 이 모델은 회귀와 분류 모두에 사용이 가능하다. 랜던 포레스트와는 달리 그래디언트 부스팅은 이전 트리의 오차를 보완하는 방식으로 순차적으로 트리를 만든다.\n",
    "기본적으로 그래디언트 부스팅 회귀 트리에는 무작위성이 없다. 대신에 강력한 가지치기 기능을 사용한다.\n",
    "그래디언트 부스팅 트리는 보통 하나에서 다섯 정도의 깊지 않은 트리를 사용하므로 메모리를 적게 사용하고 예측 또한 빠른편이다.\n",
    "\n",
    "그래디언트 부스팅 트리의 근본 아이디어는 얕은 트리같은 간단한 모델을 많이 연결하는 것이다. 각각의 트리는 ㅇ데이터의 일부에 대해서만 예측을 잘 수행할 수 있으므로 트리가 많이 추가될수록 성능이 좋아진다.\n",
    "\n",
    "앙상블 기법에서 보통 사용하는 사전 가지치기나 트리 개수 이외에도 그래디언트 부스팅에서 중요한 매개 변수는 이전트리의 오차를 얼마나 강라게 보정할 것인지를 결정하는 learning_rate이다.\n",
    "학습률이 크면 트리는 보정을 강하게 하기 때문에 복잡한 모델을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/home/moon23k/anaconda3/envs/Basic_conda_env/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mglearn\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data accuracy : 1.000\n",
      "test data accuracy : 0.965\n"
     ]
    }
   ],
   "source": [
    "gb_clf = GradientBoostingClassifier(random_state=0)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "\n",
    "print('train data accuracy : {:.3f}'.format(gb_clf.score(X_train, y_train)))\n",
    "print('test data accuracy : {:.3f}'.format(gb_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과를 보니 학습데이터 예측률이 100이다. 이는 과대적합된 것이므로 트리의 최대 깊이를 줄여 사전 가지치기를 강하게 하거나 학습률을 낮출 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data accuracy : 0.991\n",
      "test data accuracy : 0.972\n"
     ]
    }
   ],
   "source": [
    "gb_clf = GradientBoostingClassifier(random_state=0, max_depth=1)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "\n",
    "print('train data accuracy : {:.3f}'.format(gb_clf.score(X_train, y_train)))\n",
    "print('test data accuracy : {:.3f}'.format(gb_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data accuracy : 0.988\n",
      "test data accuracy : 0.965\n"
     ]
    }
   ],
   "source": [
    "gb_clf = GradientBoostingClassifier(random_state=0, learning_rate=0.01)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "\n",
    "print('train data accuracy : {:.3f}'.format(gb_clf.score(X_train, y_train)))\n",
    "print('test data accuracy : {:.3f}'.format(gb_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비슷한 종류의 데이터에서 그래디언트 부스팅과 랜덤 포레스트 둘다 잘 작동하지만, 보통 더 안정적인 랜덤 포레스트를 먼저 적용하곤 한다.\n",
    "랜덤 포레스트가 잘 작동하더라도 예측 시간이 중요하거나 머신러닝 모델에서 마지막 성능까지 쥐어짜야 할 때 그래디언트 부스팅을 사용해서 하이퍼 파라미터 튜닝으로 성능을 향상시키는 것도 하나의 방법이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
